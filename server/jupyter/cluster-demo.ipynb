{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ce7b04",
   "metadata": {},
   "source": [
    "# Kubernetes Cluster Demo Notebook\n",
    "\n",
    "This notebook demonstrates the capabilities of our three-node Kubernetes cluster:\n",
    "- **Tower**: Control plane + PostgreSQL + pgAdmin\n",
    "- **AGX**: Worker node (GPU-enabled)\n",
    "- **Nano**: Worker node (GPU-enabled, resource-constrained)\n",
    "\n",
    "## Features Demonstrated\n",
    "1. üêò PostgreSQL with pgvector extension\n",
    "2. üéØ Vector similarity search\n",
    "3. üìä Cluster resource monitoring\n",
    "4. üîó Service connectivity testing\n",
    "5. ü§ñ GPU resource detection\n",
    "6. üìà Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5dd76b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfdd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database connectivity\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "# Kubernetes client\n",
    "try:\n",
    "    from kubernetes import client, config\n",
    "    k8s_available = True\n",
    "except ImportError:\n",
    "    print(\"Installing Kubernetes client...\")\n",
    "    !pip install kubernetes\n",
    "    from kubernetes import client, config\n",
    "    k8s_available = True\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö All libraries imported successfully!\")\n",
    "print(f\"üêç Python version: {sys.version}\")\n",
    "print(f\"üïê Notebook started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f233aa65",
   "metadata": {},
   "source": [
    "## 2. Cluster Configuration and Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44dde52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database configuration\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv('POSTGRES_HOST', 'postgres-service'),\n",
    "    'port': os.getenv('POSTGRES_PORT', '5432'),\n",
    "    'database': os.getenv('POSTGRES_DB', 'vectordb'),\n",
    "    'user': os.getenv('POSTGRES_USER', 'postgres'),\n",
    "    'password': os.getenv('POSTGRES_PASSWORD', 'myscretpassword')\n",
    "}\n",
    "\n",
    "# Service endpoints\n",
    "SERVICES = {\n",
    "    'postgres': f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}\",\n",
    "    'pgadmin': 'pgadmin-service:80',\n",
    "    'fastapi_nano': 'fastapi-nano-service:8000'  # Runs exclusively on nano node\n",
    "}\n",
    "\n",
    "print(\"üîß Configuration loaded:\")\n",
    "print(f\"  üìä Database: {DB_CONFIG['host']}:{DB_CONFIG['port']}\")\n",
    "print(f\"  üéõÔ∏è  pgAdmin: {SERVICES['pgadmin']}\")\n",
    "print(f\"  üöÄ FastAPI: {SERVICES['fastapi_nano']} (nano node only)\")\n",
    "print(f\"  ‚ö†Ô∏è  Note: FastAPI requires nano node to be Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62cb0d",
   "metadata": {},
   "source": [
    "## 3. Database Connection and pgvector Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b5567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    \"\"\"Establish database connection with error handling\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Database connection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test database connection\n",
    "print(\"üîå Testing database connection...\")\n",
    "conn = get_db_connection()\n",
    "\n",
    "if conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # Check pgvector extension\n",
    "        cur.execute(\"SELECT extname, extversion FROM pg_extension WHERE extname = 'vector';\")\n",
    "        result = cur.fetchone()\n",
    "        \n",
    "        if result:\n",
    "            print(f\"‚úÖ pgvector extension: v{result[1]}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  pgvector extension not found, installing...\")\n",
    "            cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "            conn.commit()\n",
    "            print(\"‚úÖ pgvector extension installed\")\n",
    "        \n",
    "        # Get database info\n",
    "        cur.execute(\"SELECT version();\")\n",
    "        version = cur.fetchone()[0]\n",
    "        print(f\"üêò PostgreSQL: {version.split(',')[0]}\")\n",
    "        \n",
    "    conn.close()\n",
    "    print(\"‚úÖ Database connection successful!\")\n",
    "else:\n",
    "    print(\"‚ùå Could not connect to database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c1db3",
   "metadata": {},
   "source": [
    "## 4. Kubernetes Cluster Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a694be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_info():\n",
    "    \"\"\"Get comprehensive cluster information\"\"\"\n",
    "    try:\n",
    "        # Load kube config\n",
    "        config.load_incluster_config()  # For in-cluster access\n",
    "    except:\n",
    "        try:\n",
    "            config.load_kube_config()  # For local access\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è  Could not load Kubernetes config\")\n",
    "            return None\n",
    "    \n",
    "    v1 = client.CoreV1Api()\n",
    "    apps_v1 = client.AppsV1Api()\n",
    "    \n",
    "    cluster_info = {\n",
    "        'nodes': [],\n",
    "        'pods': [],\n",
    "        'services': [],\n",
    "        'deployments': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Get nodes\n",
    "        nodes = v1.list_node()\n",
    "        for node in nodes.items:\n",
    "            node_info = {\n",
    "                'name': node.metadata.name,\n",
    "                'status': 'Ready' if any(condition.type == 'Ready' and condition.status == 'True' \n",
    "                                       for condition in node.status.conditions) else 'NotReady',\n",
    "                'arch': node.status.node_info.architecture,\n",
    "                'os': node.status.node_info.operating_system,\n",
    "                'kernel': node.status.node_info.kernel_version,\n",
    "                'cpu': node.status.allocatable.get('cpu', 'unknown'),\n",
    "                'memory': node.status.allocatable.get('memory', 'unknown'),\n",
    "                'gpu': node.status.allocatable.get('nvidia.com/gpu', '0')\n",
    "            }\n",
    "            cluster_info['nodes'].append(node_info)\n",
    "        \n",
    "        # Get pods\n",
    "        pods = v1.list_pod_for_all_namespaces()\n",
    "        for pod in pods.items:\n",
    "            if pod.metadata.namespace == 'default':  # Focus on our apps\n",
    "                pod_info = {\n",
    "                    'name': pod.metadata.name,\n",
    "                    'namespace': pod.metadata.namespace,\n",
    "                    'status': pod.status.phase,\n",
    "                    'node': pod.spec.node_name,\n",
    "                    'app': pod.metadata.labels.get('app', 'unknown') if pod.metadata.labels else 'unknown'\n",
    "                }\n",
    "                cluster_info['pods'].append(pod_info)\n",
    "        \n",
    "        # Get services\n",
    "        services = v1.list_service_for_all_namespaces()\n",
    "        for svc in services.items:\n",
    "            if svc.metadata.namespace == 'default':\n",
    "                svc_info = {\n",
    "                    'name': svc.metadata.name,\n",
    "                    'type': svc.spec.type,\n",
    "                    'cluster_ip': svc.spec.cluster_ip,\n",
    "                    'ports': [f\"{port.port}:{port.target_port}\" for port in svc.spec.ports] if svc.spec.ports else []\n",
    "                }\n",
    "                cluster_info['services'].append(svc_info)\n",
    "        \n",
    "        return cluster_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting cluster info: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get and display cluster information\n",
    "print(\"üîç Gathering cluster information...\")\n",
    "cluster_info = get_cluster_info()\n",
    "\n",
    "if cluster_info:\n",
    "    print(\"\\nüèóÔ∏è  Cluster Nodes:\")\n",
    "    nodes_df = pd.DataFrame(cluster_info['nodes'])\n",
    "    print(nodes_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nüöÄ Running Pods:\")\n",
    "    pods_df = pd.DataFrame(cluster_info['pods'])\n",
    "    if not pods_df.empty:\n",
    "        print(pods_df[['name', 'app', 'status', 'node']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\nüîó Services:\")\n",
    "    services_df = pd.DataFrame(cluster_info['services'])\n",
    "    if not services_df.empty:\n",
    "        print(services_df[['name', 'type', 'cluster_ip']].to_string(index=False))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Could not retrieve cluster information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba22d4e7",
   "metadata": {},
   "source": [
    "## 5. Vector Database Demo - Document Storage and Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa62b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample documents table with vector embeddings\n",
    "def setup_vector_demo():\n",
    "    \"\"\"Set up vector database demo with sample data\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    if not conn:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # Create documents table with vector column\n",
    "            cur.execute(\"\"\"\n",
    "                DROP TABLE IF EXISTS demo_documents;\n",
    "                CREATE TABLE demo_documents (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    title TEXT NOT NULL,\n",
    "                    content TEXT NOT NULL,\n",
    "                    category TEXT,\n",
    "                    embedding vector(384),  -- Using 384-dimension vectors (sentence-transformers size)\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Sample documents about our cluster\n",
    "            sample_docs = [\n",
    "                {\n",
    "                    'title': 'Kubernetes Cluster Setup',\n",
    "                    'content': 'Our three-node Kubernetes cluster consists of a tower control plane, AGX worker with GPU acceleration, and Nano edge device for lightweight workloads.',\n",
    "                    'category': 'infrastructure'\n",
    "                },\n",
    "                {\n",
    "                    'title': 'PostgreSQL with pgvector',\n",
    "                    'content': 'PostgreSQL database enhanced with pgvector extension enables efficient vector similarity search for AI and machine learning applications.',\n",
    "                    'category': 'database'\n",
    "                },\n",
    "                {\n",
    "                    'title': 'GPU-Accelerated Computing',\n",
    "                    'content': 'Both AGX and Nano nodes feature NVIDIA GPUs with CUDA support, enabling parallel processing for deep learning and AI workloads.',\n",
    "                    'category': 'compute'\n",
    "                },\n",
    "                {\n",
    "                    'title': 'FastAPI Microservices',\n",
    "                    'content': 'Lightweight FastAPI applications deployed across worker nodes provide REST endpoints for machine learning inference and data processing.',\n",
    "                    'category': 'application'\n",
    "                },\n",
    "                {\n",
    "                    'title': 'Jupyter Lab Environment',\n",
    "                    'content': 'Interactive Jupyter Lab notebook environment for data science, machine learning experimentation, and cluster monitoring.',\n",
    "                    'category': 'development'\n",
    "                },\n",
    "                {\n",
    "                    'title': 'Network Architecture',\n",
    "                    'content': 'Multi-subnet network design with dedicated cluster communication, internet access, and external service exposure.',\n",
    "                    'category': 'networking'\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            # Generate simple embeddings (in real scenario, use sentence-transformers)\n",
    "            for doc in sample_docs:\n",
    "                # Simple embedding based on word frequency (demo purposes)\n",
    "                words = doc['content'].lower().split()\n",
    "                embedding = np.random.normal(0, 1, 384).tolist()  # Random for demo\n",
    "                \n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO demo_documents (title, content, category, embedding)\n",
    "                    VALUES (%s, %s, %s, %s)\n",
    "                \"\"\", (doc['title'], doc['content'], doc['category'], embedding))\n",
    "            \n",
    "            # Create vector index for performance\n",
    "            cur.execute(\"\"\"\n",
    "                CREATE INDEX IF NOT EXISTS demo_documents_embedding_idx \n",
    "                ON demo_documents USING ivfflat (embedding vector_cosine_ops)\n",
    "                WITH (lists = 100);\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.commit()\n",
    "            print(\"‚úÖ Vector database demo setup complete!\")\n",
    "            \n",
    "            # Show sample data\n",
    "            cur.execute(\"SELECT title, category, created_at FROM demo_documents ORDER BY id;\")\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            df = pd.DataFrame(results, columns=['Title', 'Category', 'Created'])\n",
    "            print(\"\\nüìö Sample Documents:\")\n",
    "            print(df.to_string(index=False))\n",
    "            \n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error setting up vector demo: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "setup_vector_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23eaa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector similarity search demo\n",
    "def vector_search_demo(query_text, limit=3):\n",
    "    \"\"\"Demonstrate vector similarity search\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    if not conn:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with conn.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "            # Generate query embedding (simplified for demo)\n",
    "            query_embedding = np.random.normal(0, 1, 384).tolist()\n",
    "            \n",
    "            # Perform vector similarity search\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    title,\n",
    "                    content,\n",
    "                    category,\n",
    "                    embedding <=> %s::vector AS distance\n",
    "                FROM demo_documents\n",
    "                ORDER BY embedding <=> %s::vector\n",
    "                LIMIT %s;\n",
    "            \"\"\", (query_embedding, query_embedding, limit))\n",
    "            \n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            print(f\"üîç Vector Search Results for: '{query_text}'\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            for i, result in enumerate(results, 1):\n",
    "                print(f\"\\n{i}. {result['title']} (Distance: {result['distance']:.4f})\")\n",
    "                print(f\"   Category: {result['category']}\")\n",
    "                print(f\"   Content: {result['content'][:100]}...\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Vector search error: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Demo searches\n",
    "search_queries = [\n",
    "    \"GPU computing and machine learning\",\n",
    "    \"database vector search\",\n",
    "    \"network cluster architecture\"\n",
    "]\n",
    "\n",
    "for query in search_queries:\n",
    "    vector_search_demo(query)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6fa14",
   "metadata": {},
   "source": [
    "## 6. Service Health Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_service_health():\n",
    "    \"\"\"Check health of cluster services\"\"\"\n",
    "    health_status = []\n",
    "    \n",
    "    # Check FastAPI Nano service\n",
    "    try:\n",
    "        response = requests.get('http://fastapi-nano-service:8000/health', timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            health_status.append({'Service': 'FastAPI Nano', 'Status': '‚úÖ Healthy', 'Response Time': f\"{response.elapsed.total_seconds():.3f}s\"})\n",
    "        else:\n",
    "            health_status.append({'Service': 'FastAPI Nano', 'Status': f'‚ö†Ô∏è  Status {response.status_code}', 'Response Time': 'N/A'})\n",
    "    except Exception as e:\n",
    "        health_status.append({'Service': 'FastAPI Nano', 'Status': f'‚ùå {str(e)[:50]}', 'Response Time': 'N/A'})\n",
    "    \n",
    "    # Check PostgreSQL\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        if conn:\n",
    "            with conn.cursor() as cur:\n",
    "                start_time = datetime.now()\n",
    "                cur.execute('SELECT 1')\n",
    "                end_time = datetime.now()\n",
    "                response_time = (end_time - start_time).total_seconds()\n",
    "                health_status.append({'Service': 'PostgreSQL', 'Status': '‚úÖ Healthy', 'Response Time': f\"{response_time:.3f}s\"})\n",
    "            conn.close()\n",
    "        else:\n",
    "            health_status.append({'Service': 'PostgreSQL', 'Status': '‚ùå Connection Failed', 'Response Time': 'N/A'})\n",
    "    except Exception as e:\n",
    "        health_status.append({'Service': 'PostgreSQL', 'Status': f'‚ùå {str(e)[:50]}', 'Response Time': 'N/A'})\n",
    "    \n",
    "    # Check pgAdmin (if accessible)\n",
    "    try:\n",
    "        response = requests.get('http://pgadmin-service:80', timeout=5, allow_redirects=False)\n",
    "        if response.status_code in [200, 302]:  # 302 is redirect to login\n",
    "            health_status.append({'Service': 'pgAdmin', 'Status': '‚úÖ Healthy', 'Response Time': f\"{response.elapsed.total_seconds():.3f}s\"})\n",
    "        else:\n",
    "            health_status.append({'Service': 'pgAdmin', 'Status': f'‚ö†Ô∏è  Status {response.status_code}', 'Response Time': 'N/A'})\n",
    "    except Exception as e:\n",
    "        health_status.append({'Service': 'pgAdmin', 'Status': f'‚ùå {str(e)[:50]}', 'Response Time': 'N/A'})\n",
    "    \n",
    "    # Display results\n",
    "    health_df = pd.DataFrame(health_status)\n",
    "    print(\"üè• Service Health Check\")\n",
    "    print(health_df.to_string(index=False))\n",
    "    \n",
    "    return health_df\n",
    "\n",
    "health_results = check_service_health()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f76bf1b",
   "metadata": {},
   "source": [
    "## 7. Cluster Resource Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc012799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cluster resources\n",
    "if cluster_info and cluster_info['nodes']:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Kubernetes Cluster Resource Overview', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    nodes_df = pd.DataFrame(cluster_info['nodes'])\n",
    "    \n",
    "    # Node status pie chart\n",
    "    status_counts = nodes_df['status'].value_counts()\n",
    "    axes[0, 0].pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0, 0].set_title('Node Status Distribution')\n",
    "    \n",
    "    # Architecture distribution\n",
    "    arch_counts = nodes_df['arch'].value_counts()\n",
    "    axes[0, 1].bar(arch_counts.index, arch_counts.values, color='skyblue')\n",
    "    axes[0, 1].set_title('Node Architecture')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    \n",
    "    # GPU availability\n",
    "    gpu_data = nodes_df[['name', 'gpu']].copy()\n",
    "    gpu_data['gpu'] = gpu_data['gpu'].astype(int)\n",
    "    axes[1, 0].bar(gpu_data['name'], gpu_data['gpu'], color='green')\n",
    "    axes[1, 0].set_title('GPU Resources per Node')\n",
    "    axes[1, 0].set_ylabel('GPU Count')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Service distribution\n",
    "    if cluster_info['services']:\n",
    "        services_df = pd.DataFrame(cluster_info['services'])\n",
    "        service_types = services_df['type'].value_counts()\n",
    "        axes[1, 1].pie(service_types.values, labels=service_types.index, autopct='%1.1f%%')\n",
    "        axes[1, 1].set_title('Service Type Distribution')\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'No services data', ha='center', va='center')\n",
    "        axes[1, 1].set_title('Service Type Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Node details table\n",
    "    print(\"\\nüìä Detailed Node Information:\")\n",
    "    display_columns = ['name', 'status', 'arch', 'cpu', 'memory', 'gpu']\n",
    "    print(nodes_df[display_columns].to_string(index=False))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No cluster information available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa0e93",
   "metadata": {},
   "source": [
    "## 8. Database Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_database_performance():\n",
    "    \"\"\"Analyze database performance and vector operations\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    if not conn:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with conn.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "            # Database statistics\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    schemaname,\n",
    "                    tablename,\n",
    "                    n_tup_ins as inserts,\n",
    "                    n_tup_upd as updates,\n",
    "                    n_tup_del as deletes,\n",
    "                    seq_scan as sequential_scans,\n",
    "                    idx_scan as index_scans\n",
    "                FROM pg_stat_user_tables\n",
    "                WHERE tablename = 'demo_documents';\n",
    "            \"\"\")\n",
    "            \n",
    "            stats = cur.fetchone()\n",
    "            \n",
    "            if stats:\n",
    "                print(\"üìà Database Performance Metrics:\")\n",
    "                stats_df = pd.DataFrame([dict(stats)])\n",
    "                print(stats_df.to_string(index=False))\n",
    "            \n",
    "            # Vector index information\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    indexname,\n",
    "                    indexdef\n",
    "                FROM pg_indexes \n",
    "                WHERE tablename = 'demo_documents' AND indexname LIKE '%embedding%';\n",
    "            \"\"\")\n",
    "            \n",
    "            indexes = cur.fetchall()\n",
    "            \n",
    "            if indexes:\n",
    "                print(\"\\nüîç Vector Indexes:\")\n",
    "                for idx in indexes:\n",
    "                    print(f\"  ‚Ä¢ {idx['indexname']}\")\n",
    "            \n",
    "            # Extension information\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    extname as extension,\n",
    "                    extversion as version,\n",
    "                    extrelocatable as relocatable\n",
    "                FROM pg_extension \n",
    "                WHERE extname IN ('vector', 'plpgsql');\n",
    "            \"\"\")\n",
    "            \n",
    "            extensions = cur.fetchall()\n",
    "            \n",
    "            if extensions:\n",
    "                print(\"\\nüîß Database Extensions:\")\n",
    "                ext_df = pd.DataFrame([dict(ext) for ext in extensions])\n",
    "                print(ext_df.to_string(index=False))\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing database performance: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "analyze_database_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d19b8b",
   "metadata": {},
   "source": [
    "## 9. Cluster Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41024f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ Kubernetes Cluster Demo Summary\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"‚úÖ Successfully demonstrated:\")\n",
    "print(\"  ‚Ä¢ Multi-node Kubernetes cluster operation\")\n",
    "print(\"  ‚Ä¢ PostgreSQL with pgvector extension\")\n",
    "print(\"  ‚Ä¢ Vector similarity search capabilities\")\n",
    "print(\"  ‚Ä¢ Service health monitoring\")\n",
    "print(\"  ‚Ä¢ Cluster resource visualization\")\n",
    "print(\"  ‚Ä¢ GPU resource detection\")\n",
    "print()\n",
    "print(\"üîó External Access URLs:\")\n",
    "print(\"  ‚Ä¢ Jupyter Lab: http://192.168.10.1:30888 (token: jupyter-k8s-demo)\")\n",
    "print(\"  ‚Ä¢ pgAdmin: http://192.168.10.1:30080 (pgadmin@pgadmin.org/pgadmin)\")\n",
    "print(\"  ‚Ä¢ PostgreSQL: 192.168.10.1:30432 (postgres/postgres)\")\n",
    "print()\n",
    "print(\"üöÄ Next Steps:\")\n",
    "print(\"  1. Deploy machine learning models on GPU nodes\")\n",
    "print(\"  2. Implement distributed training workflows\")\n",
    "print(\"  3. Set up monitoring with Prometheus + Grafana\")\n",
    "print(\"  4. Add CI/CD pipelines with GitOps\")\n",
    "print(\"  5. Implement auto-scaling policies\")\n",
    "print()\n",
    "print(\"üìö Additional Features Available:\")\n",
    "print(\"  ‚Ä¢ NFS shared storage across all nodes\")\n",
    "print(\"  ‚Ä¢ Private container registry\")\n",
    "print(\"  ‚Ä¢ GPU scheduling and resource management\")\n",
    "print(\"  ‚Ä¢ Multi-architecture support (ARM64/AMD64)\")\n",
    "print()\n",
    "print(f\"‚è∞ Demo completed at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a221c13",
   "metadata": {},
   "source": [
    "## 10. Nano Agent Setup Process\n",
    "\n",
    "The nano node is currently in **NotReady** status. The nano agent has a dedicated setup script that performs comprehensive initialization including container build, k3s agent setup, and service deployment.\n",
    "\n",
    "### Complete Agent Setup Process\n",
    "\n",
    "The `setup_fastapi_nano.sh` script performs these operations:\n",
    "\n",
    "#### üèóÔ∏è Container Build Process\n",
    "1. **Build from Dockerfile + devcontainer.json**\n",
    "   - Uses nano-specific dockerfile.nano.req\n",
    "   - Includes devcontainer.json configuration\n",
    "   - **Jupyter Lab is pre-installed** in the base image\n",
    "   - Builds FastAPI nano application container\n",
    "\n",
    "#### ‚öôÔ∏è Kubernetes Agent Setup\n",
    "2. **Install k3s Agent**\n",
    "   - Download and install k3s agent\n",
    "   - Configure with tower server token\n",
    "   - Set up secure certificates\n",
    "   - Configure insecure registry access\n",
    "\n",
    "3. **Join Cluster**\n",
    "   - Connect to tower control plane (192.168.5.1:6443)\n",
    "   - Register as worker node\n",
    "   - Establish cluster networking\n",
    "\n",
    "#### üöÄ Application Deployment\n",
    "4. **Deploy FastAPI Application**\n",
    "   - Execute fastapi_app.py\n",
    "   - Configure nano-specific settings\n",
    "   - Set up health checks (fastapi_healthcheck.py)\n",
    "   - Initialize database if needed (init_db.sql)\n",
    "\n",
    "5. **Start Services**\n",
    "   - **FastAPI**: Port 8000 (NodePort 30002)\n",
    "   - **Jupyter Lab**: Via start-jupyter.sh\n",
    "   - Both services accessible via cluster network\n",
    "\n",
    "### Available Scripts on Nano Device\n",
    "```bash\n",
    "# Located in: ~/containers/kubernetes/agent/nano/src/\n",
    "backup_home.sh              # Backup nano home directory\n",
    "fastapi_app.py              # Main FastAPI application\n",
    "fastapi_healthcheck.py      # Health check endpoint\n",
    "init_db.sql                 # Database initialization\n",
    "main.py                     # Application entry point\n",
    "restart_fastapi_nano.sh     # Restart FastAPI service\n",
    "setup_fastapi_nano.sh       # MAIN SETUP SCRIPT\n",
    "start-jupyter.sh            # Start Jupyter Lab service\n",
    "```\n",
    "\n",
    "### Execution Steps (You're Already on Nano!)\n",
    "```bash\n",
    "# Current location: sanjay@nano:~/containers/kubernetes/agent/nano/src$\n",
    "\n",
    "# Execute the main setup script\n",
    "bash setup_fastapi_nano.sh\n",
    "\n",
    "# Optional: Run with debug for detailed output\n",
    "DEBUG=1 bash setup_fastapi_nano.sh\n",
    "```\n",
    "\n",
    "### What the Script Will Accomplish\n",
    "- ‚úÖ **Container Build**: FastAPI nano image with Jupyter pre-installed\n",
    "- ‚úÖ **k3s Agent**: Properly configured and joined to cluster\n",
    "- ‚úÖ **FastAPI Service**: Running fastapi_app.py on port 8000\n",
    "- ‚úÖ **Jupyter Service**: Available via start-jupyter.sh\n",
    "- ‚úÖ **Health Monitoring**: fastapi_healthcheck.py operational\n",
    "- ‚úÖ **Database Setup**: init_db.sql if database required\n",
    "- ‚úÖ **Service Restart**: restart_fastapi_nano.sh for maintenance\n",
    "\n",
    "### Expected Final State\n",
    "```\n",
    "nano node: NotReady ‚Üí Ready\n",
    "fastapi-nano pod: Pending ‚Üí Running (on nano node only)\n",
    "FastAPI: http://192.168.10.1:30002\n",
    "Jupyter: Available within nano container\n",
    "Health Check: /health endpoint operational\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca8e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nano device is ready for setup script execution\n",
    "print(\"üéØ Nano Agent Setup Ready for Execution\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check current cluster status from tower perspective\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Get node status\n",
    "    result = subprocess.run(['kubectl', 'get', 'nodes', '-o', 'json'], \n",
    "                          capture_output=True, text=True, timeout=10)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        nodes_data = json.loads(result.stdout)\n",
    "        \n",
    "        print(\"\\nüìä Current Cluster Status (from Tower):\")\n",
    "        for node in nodes_data['items']:\n",
    "            name = node['metadata']['name']\n",
    "            \n",
    "            # Check ready condition\n",
    "            ready_status = \"Unknown\"\n",
    "            for condition in node['status']['conditions']:\n",
    "                if condition['type'] == 'Ready':\n",
    "                    ready_status = \"Ready\" if condition['status'] == 'True' else \"NotReady\"\n",
    "                    break\n",
    "            \n",
    "            status_emoji = \"‚úÖ\" if ready_status == \"Ready\" else \"‚ùå\"\n",
    "            print(f\"  {status_emoji} {name}: {ready_status}\")\n",
    "            \n",
    "            if name == 'nano':\n",
    "                print(f\"      ‚îî‚îÄ‚îÄ üéØ User is positioned on nano device!\")\n",
    "                print(f\"      ‚îî‚îÄ‚îÄ üìÅ Location: ~/containers/kubernetes/agent/nano/src/\")\n",
    "                print(f\"      ‚îî‚îÄ‚îÄ üîß Ready to run: setup_fastapi_nano.sh\")\n",
    "    \n",
    "    # Check FastAPI nano pod status\n",
    "    result = subprocess.run(['kubectl', 'get', 'pods', '-l', 'app=fastapi-nano', '-o', 'json'], \n",
    "                          capture_output=True, text=True, timeout=10)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        pods_data = json.loads(result.stdout)\n",
    "        \n",
    "        print(f\"\\nüöÄ FastAPI Nano Pod Status:\")\n",
    "        if pods_data['items']:\n",
    "            for pod in pods_data['items']:\n",
    "                name = pod['metadata']['name']\n",
    "                status = pod['status']['phase']\n",
    "                \n",
    "                status_emoji = \"‚úÖ\" if status == \"Running\" else \"‚è≥\" if status == \"Pending\" else \"‚ùå\"\n",
    "                print(f\"  {status_emoji} {name}: {status}\")\n",
    "                \n",
    "                if status == \"Pending\":\n",
    "                    print(f\"      ‚îî‚îÄ‚îÄ ‚è≥ Waiting for nano agent setup completion\")\n",
    "        else:\n",
    "            print(\"  ‚ÑπÔ∏è  No FastAPI nano pods found\")\n",
    "\n",
    "    print(f\"\\nüõ†Ô∏è Available Setup Scripts on Nano:\")\n",
    "    nano_scripts = [\n",
    "        \"setup_fastapi_nano.sh       # üéØ MAIN SETUP SCRIPT\",\n",
    "        \"fastapi_app.py              # FastAPI application\",\n",
    "        \"fastapi_healthcheck.py      # Health monitoring\",\n",
    "        \"start-jupyter.sh            # Jupyter Lab startup\",\n",
    "        \"restart_fastapi_nano.sh     # Service restart\",\n",
    "        \"backup_home.sh              # Home backup utility\",\n",
    "        \"init_db.sql                 # Database initialization\",\n",
    "        \"main.py                     # Application entry point\"\n",
    "    ]\n",
    "    \n",
    "    for script in nano_scripts:\n",
    "        print(f\"  üìú {script}\")\n",
    "\n",
    "    print(f\"\\n‚ö° Ready to Execute:\")\n",
    "    print(f\"  üíª Current position: sanjay@nano:~/containers/kubernetes/agent/nano/src$\")\n",
    "    print(f\"  üöÄ Command: bash setup_fastapi_nano.sh\")\n",
    "    print(f\"  üîç Debug mode: DEBUG=1 bash setup_fastapi_nano.sh\")\n",
    "    print(f\"\")\n",
    "    print(f\"üéØ This will:\")\n",
    "    print(f\"  ‚Ä¢ Build nano container with Jupyter + FastAPI\")\n",
    "    print(f\"  ‚Ä¢ Install and configure k3s agent\")\n",
    "    print(f\"  ‚Ä¢ Join nano node to cluster\")\n",
    "    print(f\"  ‚Ä¢ Deploy and start all services\")\n",
    "    print(f\"  ‚Ä¢ Make nano node Ready and pod Running\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚ùå Kubectl command timed out\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"‚ùå Kubectl command failed: {e}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"‚ùå Failed to parse kubectl output\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error checking cluster status: {e}\")\n",
    "\n",
    "print(f\"\\n‚ú® You're perfectly positioned to run the setup!\")\n",
    "print(f\"   Execute: bash setup_fastapi_nano.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e30ca",
   "metadata": {},
   "source": [
    "### Jupyter Lab Architecture in Our Cluster\n",
    "\n",
    "Our cluster has **two distinct Jupyter Lab instances**:\n",
    "\n",
    "#### üèóÔ∏è Tower Jupyter Lab (Current Instance)\n",
    "- **Location**: Running on tower node (control plane)\n",
    "- **Purpose**: Cluster monitoring, admin tasks, this demo notebook\n",
    "- **Access**: http://192.168.10.1:30888\n",
    "- **Image**: jupyter/tensorflow-notebook:latest\n",
    "- **Status**: Currently running (where this notebook executes)\n",
    "\n",
    "#### ü§ñ Nano Jupyter Lab (Agent Container)\n",
    "- **Location**: Will run inside FastAPI nano container\n",
    "- **Purpose**: Edge computing, nano-specific development\n",
    "- **Access**: Internal to nano container (part of agent setup)\n",
    "- **Image**: Built with dockerfile.nano.req + devcontainer.json\n",
    "- **Status**: Will be available after nano agent setup completes\n",
    "\n",
    "Both instances serve different purposes:\n",
    "- **Tower**: Cluster-wide monitoring and administration\n",
    "- **Nano**: Edge-specific development and testing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
