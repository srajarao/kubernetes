# syntax=docker/dockerfile:1.7

# Start FROM an official NVIDIA TensorFlow container for aarch64 (DGX Spark)
FROM --platform=linux/arm64 nvcr.io/nvidia/tensorflow:25.02-tf2-py3

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive \
    PIP_NO_CACHE_DIR=1 \
    PYTHONUNBUFFERED=1 \
    # --- Define VENV Path ---
    VIRTUAL_ENV=/opt/venv \
    PATH="/opt/venv/bin:$PATH"

# --- Switch to root to install system packages ---
USER root

# --- Install postgresql-client ---
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        postgresql-client \
        # Add python3-venv if not already present (TF image likely has it)
        python3-venv \
    && rm -rf /var/lib/apt/lists/*

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        postgresql-client \
        python3-venv \
        libcusparselt0 \
    && rm -rf /var/lib/apt/lists/*


# --- Venv Setup ---
# Get the python version from the base image (likely python3.12)
RUN python3 -m venv --system-site-packages $VIRTUAL_ENV
# Activate venv for subsequent RUN commands (by modifying PATH)
# Note: Subsequent RUN commands inherit the ENV PATH modification
RUN $VIRTUAL_ENV/bin/pip install --upgrade pip setuptools wheel

# --- Install Python Packages (using VENV pip) ---
# Install Keras (if needed, might already be there)
RUN pip install keras

# Install PyTorch with CUDA 13.0 for GB10 support
RUN pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu130

# Copy requirements and install Python packages
COPY requirements.spark1.txt /app/requirements.spark1.txt
RUN pip install -r /app/requirements.spark1.txt

# --- Switch back to non-root user (Recommended) ---
# The base TF image often defines a user like 'tensorflow' or 'nvidia'.
# Check the base image or use 'id' command inside to find the user/group.
# RUN groupadd -r appuser && useradd -r -g appuser appuser
# RUN chown -R appuser:appuser /app /opt/venv
# USER appuser

# --- App Setup & CMD ---
COPY spark1_app.py /app/spark1_app.py
COPY app/config/ /app/app/config/
WORKDIR /app
CMD ["python3", "/app/spark1_app.py"]
