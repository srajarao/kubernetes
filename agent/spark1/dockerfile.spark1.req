# syntax=docker/dockerfile:1.7
# Use NVIDIA CUDA runtime image that includes GPU drivers
FROM nvcr.io/nvidia/cuda:12.4.0-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive \
     PIP_NO_CACHE_DIR=1 \
     PYTHONUNBUFFERED=1 \
     VIRTUAL_ENV=/opt/venv \
     PATH="/opt/venv/bin:$PATH"

USER root

# Copy requirements file
COPY requirements.spark1.txt /app/requirements.spark1.txt

# OS + Python deps
RUN --mount=type=cache,target=/var/cache/apt \
        apt-get update && \
        apt-get install -y --no-install-recommends \
            python3.10 python3.10-venv  \
            ca-certificates curl wget git build-essential \
            libopenblas0 libgomp1 postgresql-client && \
    rm -rf /var/lib/apt/lists/*

# Install pip for Python 3.10
RUN curl -sS https://bootstrap.pypa.io/get-pip.py -o get-pip.py && \
    python3.10 get-pip.py && \
    rm get-pip.py

# --- Venv Setup ---
RUN python3.10 -m venv --system-site-packages $VIRTUAL_ENV
RUN $VIRTUAL_ENV/bin/pip install --upgrade pip setuptools wheel

# --- BEGIN PYTORCH and TENSORFLOW INSTALLATION ---

# Copy local files into the container
COPY wheels/tensorflow-2.16.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl /app/
COPY test_app.py /app/
COPY requirements.spark1.txt /app/requirements.spark1.txt

# Install a compatible numpy version first
RUN $VIRTUAL_ENV/bin/pip install numpy==1.26.4

# Install PyTorch for ARM64/aarch64
# As per pytorch.org, for Linux/aarch64/Pip/Python/CUDA 11.8
RUN $VIRTUAL_ENV/bin/pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install the downloaded TensorFlow wheel
RUN $VIRTUAL_ENV/bin/pip install /app/tensorflow-2.16.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl

# --- END PYTORCH and TENSORFLOW INSTALLATION ---

# 2. Install all other packages from requirements.txt
RUN $VIRTUAL_ENV/bin/pip install -r /app/requirements.spark1.txt

# Copy application code
COPY spark1_app.py /app/spark1_app.py
COPY app/config/ /app/app/config/

# Create necessary directories
RUN mkdir -p /app/app/logs /app/app/data /mnt/vmstore

# Expose ports
EXPOSE 8888
EXPOSE 8000
EXPOSE 8001

# Set the default command for the container
WORKDIR /app
CMD ["python3", "/app/spark1_app.py"]
